{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.getcwd()\n",
    "data_dir = os.join.path(parent_dir, 'dataset')\n",
    "\n",
    "class Resize:\n",
    "    \"\"\"Resize the image in a sample to a given size.\n",
    "    \n",
    "    The input could be ndarray/tensor or PIL.Image format.\n",
    "    Vast majority of PyTorch COMPOSE functions process PIL.Image input format.\n",
    "\n",
    "    Args:\n",
    "        output_D (tuple): Desired HxW size of the output image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_D=(224,224)):\n",
    "        self.output_D = output_D\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            _img = img.numpy()\n",
    "\n",
    "        elif isinstance(img, np.ndarray):\n",
    "            _img = deepcopy(img)\n",
    "\n",
    "        elif isinstance(img, PIL.Image.Image):\n",
    "            _img = np.array(img) # the image is already 3D, doesn't need the conv layer\n",
    "\n",
    "        else:\n",
    "            raise Exception\n",
    "\n",
    "        _img = cv2.resize(_img, self.output_D)\n",
    "        \n",
    "        return _img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = Resize(output_D=(224,224))\n",
    "compose = transforms.Compose([resize, transforms.ToTensor()])\n",
    "image_datasets = datasets.ImageFolder(os.path.join(data_dir, 'train'), compose)\n",
    "dataloaders = torch.utils.data.DataLoader(image_datasets, batch_size=32, shuffle=True, num_workers=2)\n",
    "class_names = image_datasets.classes\n",
    "\n",
    "# _iter_dataloaders = iter(dataloaders)\n",
    "# _img_check = next(_iter_dataloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning\n",
    "\n",
    "checkpoint = torch.load(os.join(parent_dir, 'model', 'resnet50_places365.pth.tar'))\n",
    "\n",
    "checkpoint_copy = deepcopy(checkpoint)\n",
    "checkpoint['state_dict'] = OrderedDict()\n",
    "\n",
    "# We need to change the name of every params since the model was trained using older version of PyTorch\n",
    "for k, v in checkpoint_copy['state_dict'].items():\n",
    "    _k = re.sub('module.', '', k)\n",
    "    checkpoint['state_dict'][_k] = v\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 365)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# We do this twice\n",
    "# The previous one, we want to load all params (including FCN)\n",
    "# The second one, we replace the 365 classes into 13 classes (according to our dataset)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "dataset_sizes = len(image_datasets)\n",
    "\n",
    "epochs = 120\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "    print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "     \n",
    "    # Set to training mode\n",
    "    model.train()\n",
    "     \n",
    "    # Loss and Accuracy within the epoch\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(dataloaders):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clean existing gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass - compute outputs on input data using the model\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute the total loss for the batch and add it to train_loss\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Compute the accuracy\n",
    "        ret, predictions = torch.max(outputs.data, 1)\n",
    "        correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "        # Convert correct_counts to float and then compute the mean\n",
    "        acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "        # Compute total accuracy in the whole batch and add to train_acc\n",
    "        train_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "    print(\"Epoch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(epoch, loss.item(), acc.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss}, os.path.join(parent_dir, 'model/resnet50_hw1.pth.tar'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, im):\n",
    "    _im = cv2.imread(im)\n",
    "    _im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    im_tensor = compose(_im)\n",
    " \n",
    "    if torch.cuda.is_available():\n",
    "        im_tensor = im_tensor.view(1, 3, 224, 224).cuda()\n",
    "    else:\n",
    "        raise Exception\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Model outputs log probabilities\n",
    "        out = model(im_tensor)\n",
    "        ps = torch.exp(out)\n",
    "        topk, topclass = ps.topk(1, dim=1)\n",
    "        return class_names[ps.topk(1, dim=1).indices.cpu().numpy()[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "predictions = []\n",
    "test_dir = os.join.path(parent_dir, 'dataset', 'test')\n",
    "\n",
    "for filename in os.listdir(test_dir):\n",
    "    filenames.append(filename)\n",
    "    predictions.append(predict(model, os.join.path(test_dir, filename)))\n",
    "    \n",
    "filenames_replaced = [filename.replace('.jpg','') for filename in filenames]\n",
    "\n",
    "report = pd.DataFrame({'id':filenames_replaced, 'label':predictions})\n",
    "# Submit the CSV to Kaggle\n",
    "report.to_csv(os.join.path(parent_dir, 'report.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
