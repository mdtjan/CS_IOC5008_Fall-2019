{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process was done by YOLOv2 (AlexeyAB)\n",
    "# The code is available at https://github.com/AlexeyAB/darknet/tree/47c7af1cea5bbdedf1184963355e6418cb8b1b4f\n",
    "# Please import this Notebook into 'darknet' folder that you just cloned from the Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import *\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from darknet import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_repetition= {1:int(1.88*13861),\n",
    "    2:int(2.77*10585),\n",
    "    3:int(3.70*8497),\n",
    "    4:int(4.36*7458),\n",
    "    5:int(4.81*6882),\n",
    "    6:int(5.98*5727),\n",
    "    7:int(6.14*5595),\n",
    "    8:int(6.92*5045),\n",
    "    9:int(7.58*4659),\n",
    "    10:int(7.08*4948)}\n",
    "\n",
    "# true_random from Quantumrandom package\n",
    "random_img_idx = np.load('./true_random.npy', allow_pickle=True)\n",
    "random_img_idx = list(random_img_idx)\n",
    "_temp = [random_img_idx[-1] for i in range(10)]\n",
    "random_img_idx += _temp\n",
    "\n",
    "# flatten\n",
    "_temp = []\n",
    "for i in random_img_idx:\n",
    "    for j in i:\n",
    "        _temp.append(j)\n",
    "\n",
    "np.random.seed(123)\n",
    "random_img_idx = _temp\n",
    "random_img_idx+=random_img_idx\n",
    "\n",
    "np.random.shuffle(random_img_idx)\n",
    "\n",
    "num_of_repetition_flatten = []\n",
    "for k,v in num_of_repetition.items():\n",
    "    for j in range(v):\n",
    "        num_of_repetition_flatten.append(k)\n",
    "\n",
    "np.random.shuffle(num_of_repetition_flatten)\n",
    "\n",
    "\n",
    "train_dir = './data/SVHN/train/'\n",
    "filenames = os.listdir(train_dir)\n",
    "save_dir = './data/SVHN/im_aug/'\n",
    "\n",
    "train_label_dir = './data/SVHN_labels/'\n",
    "train_label_listdir = os.listdir(train_label_dir)\n",
    "\n",
    "class_dir = './data/SVHN/number_images/'\n",
    "class_listdir = os.listdir(class_dir)    \n",
    "\n",
    "idx1 = 0\n",
    "idx2 = 0\n",
    "\n",
    "while True:\n",
    "    # Get filename of image that we want to be changed\n",
    "    filename = train_label_listdir[random_img_idx[idx1]]\n",
    "\n",
    "    # Get its annotation\n",
    "    with open(train_label_dir+filename, 'r') as f:\n",
    "        annotation = f.read()\n",
    "\n",
    "    annotation = annotation.split('\\n')\n",
    "    annotation = [i.split(' ') for i in annotation]\n",
    "\n",
    "    # Get its image\n",
    "    im_filename = filename.replace('.txt', '.png')\n",
    "    _im = cv2.imread(train_dir+im_filename)\n",
    "    H, W, _ = _im.shape\n",
    "\n",
    "    _new_annotation =  []\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            _cls_f = class_listdir[idx2]\n",
    "        except:\n",
    "            idx2 = 0\n",
    "            _cls_f = class_listdir[idx2]\n",
    "\n",
    "        _class = _cls_f.strip('.jpg')\n",
    "        _class = _class.split('_')[-1]\n",
    "        _class_im = cv2.imread(class_dir+_cls_f)\n",
    "\n",
    "        # Stopping criterion\n",
    "        if len(annotation) == 0:\n",
    "            temp_ant = '\\n'.join([' '.join(i) for i in _new_annotation])\n",
    "\n",
    "            with open(save_dir+str(idx1)+'.txt', 'w') as g:\n",
    "                g.write(temp_ant)\n",
    "            break\n",
    "\n",
    "        if not int(_class) in num_of_repetition_flatten:\n",
    "            idx2+=1\n",
    "        else:\n",
    "            ant_inf = annotation[0]\n",
    "            cx = float(ant_inf[1]) * W\n",
    "            cy = float(ant_inf[2]) * H\n",
    "            x_ = float(ant_inf[3]) * W\n",
    "            y_ = float(ant_inf[4]) * H\n",
    "            \n",
    "            if not cx:                \n",
    "                _new_annotation += [annotation.pop(0)]\n",
    "                _new_annotation[-1][0] = str(_class)\n",
    "                \n",
    "            else:\n",
    "                pop_idx = num_of_repetition_flatten.index(int(_class))\n",
    "                num_of_repetition_flatten.pop(pop_idx)\n",
    "\n",
    "                if cx-x_/2 < 0:\n",
    "                    if ant_inf[0] != '1':\n",
    "                        _im_num = _im[int(cy-y_/2):int(cy+y_/2), 0:int(cx+x_/2),:]\n",
    "                        _im_num_H, _im_num_W, _ = _im_num.shape\n",
    "                        temp = cv2.resize(_class_im, (_im_num_W, _im_num_H))\n",
    "                        _im[int(cy-y_/2):int(cy+y_/2), 0:int(cx+x_/2),:] = temp\n",
    "\n",
    "                    else:\n",
    "                        _new_annotation += [annotation.pop(0)]\n",
    "\n",
    "                else:\n",
    "                    _im_num = _im[int(cy-y_/2):int(cy+y_/2), int(cx-x_/2):int(cx+x_/2),:]\n",
    "                    _im_num_H, _im_num_W, _ = _im_num.shape\n",
    "                    temp = cv2.resize(_class_im, (_im_num_W, _im_num_H))\n",
    "                    _im[int(cy-y_/2):int(cy+y_/2), int(cx-x_/2):int(cx+x_/2),:] = temp\n",
    "\n",
    "                # New annotation\n",
    "                _new_annotation += [annotation.pop(0)]\n",
    "                _new_annotation[-1][0] = str(_class)\n",
    "                idx2+=1\n",
    "\n",
    "    # save new image\n",
    "    cv2.imwrite(save_dir+str(idx1)+'.jpg', _im)\n",
    "\n",
    "    idx1+=1\n",
    "\n",
    "    if len(num_of_repetition_flatten) == 0:\n",
    "        break\n",
    "\n",
    "    if len(num_of_repetition_flatten) % 1000 == 0:\n",
    "        percentage = (1 - (len(num_of_repetition_flatten))/326291)*100\n",
    "        print('percentage: {0:.3f}'.format(percentage))\n",
    "\n",
    "print('Finish!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is available at https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    " \n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    " \n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    " \n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    " \n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    " \n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    " \n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    " \n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    " \n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    " \n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/home/dominikus/study/deep-learning-visual-recognition/HW3/dataset/SVHN_HW/test'\n",
    "test_img = os.listdir(test_dir)\n",
    "\n",
    "# order ascendingly, order matter\n",
    "test_img = [int(i.strip('.png')) for i in test_img]\n",
    "test_img.sort()\n",
    "test_img = [str(i)+'.png' for i in test_img]\n",
    "\n",
    "weight = '/home/dominikus/darknet/backup/yolov2_last.weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 0.2, no nms\n",
    "detection_02_nonms = []\n",
    "for idx, i in enumerate(test_img):\n",
    "    # im_path = dir_+i\n",
    "    im_path = test_dir+'/'+i\n",
    "    detection_02_nonms.append(performDetect(imagePath=im_path, thresh= 0.2, configPath = \"./cfg/yolov2.cfg\", weightPath = \"./backup/yolov2_last.weights\", metaPath= \"./data/svhn.data\", showImage= False, makeImageOnly = False, initOnly= False))\n",
    "    if idx % 500 == 0:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n[('5',\\n  0.7317580580711365,\\n  (49.79778289794922,\\n   23.197275161743164,\\n   19.09353256225586,\\n   35.48165512084961))]\\n\\nplt.imshow(iim[23-17:23+17, 49-9:49+9,:])\\nround int aja\\n\\nchange the annotation into submission format\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yolo_pred2hw_submission(_input):\n",
    "    \n",
    "    if not _input:\n",
    "        return {\"bbox\":None, \"score\":None, \"label\":None}\n",
    "    \n",
    "    labels = []\n",
    "    bboxes = []\n",
    "    scores = []\n",
    "    \n",
    "    # if labels == 0, change to 10\n",
    "    \n",
    "    for i in _input:\n",
    "        if i[0] == '0':\n",
    "            labels.append(10)\n",
    "        else:\n",
    "            labels.append(int(i[0]))\n",
    "\n",
    "        scores.append(i[1])\n",
    "\n",
    "        y1 = int(i[2][1]-i[2][3]/2)\n",
    "        x1 = int(i[2][0]-i[2][2]/2)\n",
    "        y2 = int(i[2][1]+i[2][3]/2)\n",
    "        x2 = int(i[2][0]+i[2][2]/2)\n",
    "        bboxes.append((y1,x1,y2,x2))\n",
    "    \n",
    "    return {\"bbox\":bboxes, \"score\":scores, \"label\":labels}\n",
    "    \n",
    "    # these formats are equivalent:\n",
    "    # hw submission format (y1, x1, y2, x2)\n",
    "    # opencv rectangle format (x1,y1), (x2,y2)\n",
    "    # matplotlib format im[y1:y2, x1:x2, :]\n",
    "    # NMS, create matrix with format (x1,y1,x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_02_nonms = [yolo_pred2hw_submission(i) for i in detection_02_nonms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission_02_nonms.json', 'w') as f:\n",
    "    json.dump(submission_02_nonms, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 0.3, no nms\n",
    "detection_03_nonms = []\n",
    "for idx, i in enumerate(test_img):\n",
    "    # im_path = dir_+i\n",
    "    im_path = test_dir+'/'+i\n",
    "    detection_03_nonms.append(performDetect(imagePath=im_path, thresh= 0.3, configPath = \"./cfg/yolov2.cfg\", weightPath = \"./backup/yolov2_last.weights\", metaPath= \"./data/svhn.data\", showImage= False, makeImageOnly = False, initOnly= False))\n",
    "    if idx % 500 == 0:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_03_nonms = [yolo_pred2hw_submission(i) for i in detection_03_nonms]\n",
    "\n",
    "with open('submission_03_nonms.json', 'w') as f:\n",
    "    json.dump(submission_03_nonms, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(_input, threshold):\n",
    "    # input is hw submission format\n",
    "\n",
    "    if not _input['bbox']:\n",
    "        return {\"bbox\":None, \"score\":None, \"label\":None}\n",
    "\n",
    "    bboxes = np.zeros((len(_input['bbox']), 4))\n",
    "\n",
    "    for idx, i in enumerate(_input['bbox']):\n",
    "        _temp = np.array([i[1], i[0], i[3], i[2]])\n",
    "        bboxes[idx,:] = _temp\n",
    "    \n",
    "    nms_res = non_max_suppression_fast(bboxes, threshold)\n",
    "    # return nms_res\n",
    "    \n",
    "    new_labels = []\n",
    "    new_scores = []\n",
    "    new_bbox = []\n",
    "\n",
    "    for row in range(len(nms_res)):\n",
    "        _idx = np.where(np.all(bboxes == nms_res[row,:], axis=1))[0][0]\n",
    "        new_bbox.append(_input['bbox'][_idx])\n",
    "        new_labels.append(_input['label'][_idx])\n",
    "        new_scores.append(_input['score'][_idx])\n",
    "        \n",
    "    return {\"bbox\":new_bbox, \"score\":new_scores, \"label\":new_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_1 : threshold 0.2, no nms\n",
    "# submission_2 : threshold 0.3, no nms\n",
    "\n",
    "# threshold 0.2, nms 0.5\n",
    "submission_3 = [nms(i, 0.5) for i in submission_02_nnms]\n",
    "\n",
    "# threshold 0.2, nms 0.6\n",
    "submission_4 = [nms(i, 0.6) for i in submission_02_nnms]\n",
    "\n",
    "# threshold 0.2, nms 0.7\n",
    "submission_5 = [nms(i, 0.7) for i in submission_02_nnms]\n",
    "\n",
    "# threshold 0.3, nms 0.5\n",
    "submission_6 = [nms(i, 0.5) for i in submission_03_nnms]\n",
    "\n",
    "# threshold 0.3, nms 0.6\n",
    "submission_7 = [nms(i, 0.6) for i in submission_03_nnms]\n",
    "\n",
    "# threshold 0.3, nms 0.7\n",
    "submission_8 = [nms(i, 0.7) for i in submission_03_nnms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission_3.json', 'w') as f:\n",
    "    json.dump(submission_3, f)\n",
    "    \n",
    "with open('submission_4.json', 'w') as f:\n",
    "    json.dump(submission_4, f)\n",
    "    \n",
    "with open('submission_5.json', 'w') as f:\n",
    "    json.dump(submission_5, f)\n",
    "    \n",
    "with open('submission_6.json', 'w') as f:\n",
    "    json.dump(submission_6, f)\n",
    "    \n",
    "with open('submission_7.json', 'w') as f:\n",
    "    json.dump(submission_7, f)\n",
    "    \n",
    "with open('submission_8.json', 'w') as f:\n",
    "    json.dump(submission_8, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
